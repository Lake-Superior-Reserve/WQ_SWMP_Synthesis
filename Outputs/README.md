# Outputs Folder  

The structure of this folder mirrors that of `R/Analyses_for_paper`. Sub-folders exist for each of the different steps beyond the processed data.  


## 01_calculated_medians  

Based on the monthly processed data files, overall medians were calculated for WQ, NUT, and MET parameters. For NUT parameters, regression on order statistics (ROS) was used to account for censored data. At HUD stations, NO3 was used as a proxy for NO23.  



## 01b_median-clustering-DP-CF  

These files were generated by Dave Parrish and Carl Friedrichs at VIMS/CBV NERR based on their PCAs and clustering of overall, long-term water quality medians. They had been working on this clustering before this large synthesis project, and all involved decided the synergy made it worth including in this work. In May 2024, they generated updated outputs based on the medians calculated in this project (different qa/qc choices had been made and censored data were dealt with differently).   


## 02_calculated_long-term-trends  


`long-term-trends.RData` contains all calculated WQ, MET, and NUT trends, as separate data frames. `trends_df` contains WQ trends, `trends_met` contains MET trends, and `trends_nut` contains NUT trends. generated by `R/Analyses_for_paper/02_long-term-trend_analyses.Rmd`.  

`long-term-trends.csv` contains all calculated WQ, MET, and NUT trends, bound together in one table. generated by `R/Analyses_for_paper/02_long-term-trend_analyses.Rmd`.  

Both files have the same fields (columns), laid out in `data_dictionary_trend_analyses.csv`.  

Parameters on which trends were calculated are described in `data_dictionary_trend_parameters.csv`, with additional detail in the `R/Data_processing` folder README.  

### bam_outputs folder  

Individual station/parameter outputs from running the GAMs were saved as individual `.RData` files in case they need further examination (e.g. appraising the residuals and/or predicting other values). The naming convention for these files is `stationname_parameter_bam.RData`.  



## 03_calculated_seasonality  

`seasonal_amplitude_medians.rds/.csv` This is a data frame containing median seasonal amplitude of temp, chla, and DO by station, as calculated in `R/Analyses_for_paper/03_seasonalAmplitude_and_itsTrends.Rmd`  


`seasonal_amplitude_trends.rds/csv` data frame containing the estimates for trend (per year), se, and p-values for chl, DO mg/L, and temperature normalized seasonal amplitudes. As of 2/23/2024 autocorrelation has not been accounted for, so p-values are probably too low. generated by `R/Analyses_for_paper/03_seasonalAmplitude_and_itsTrends.Rmd`  

## 04_compiled_predictors  


## 05_predictive_modeling  


## 06_model_selection  

### R_objects folder  

This folder contains `.RData` objects for each response with output from model dredging (`out` in the file name) and model averaging (`post-averaging` in the file name). I'm using `chl` in describing objects here, but for `domgl` and `doLT2` objects, replace `chl` with the appropriate response.   

`out` objects contain the following:  

-  `chla_subsets` - a data.frame that is also a model.selection object, containing information on each of the models generated from the use of `MuMIn::dredge()` on the global model.  
-  `dat_chl` - the data frame used to generate the global model. All variables have been centered and scaled to 1 standard deviation.    
-  `mod_chl` - the global model object from which subsets were generated.  



`post-averaging` objects contain the following:  

-  `coeffs_stnd` - table of standardized coefficients from averaging a top model set of delta < 4.  
-  `dat_chl` - the data frame used to generate the global model. All variables have been centered and scaled to 1 standard deviation.   
-  `dat_means` - a data frame with a single row containing the mean for each variable. Used with `dat_chl` and `dat_sds` to back-calculate to original units from standardized units.  
-  `dat_sds` - a data frame with a single row containing the standard deviation of each variable. Used with `dat_chl` and `dat_means` to back-calculate to original units.  
-  `mod_avgd2` / `d4` / `d6` - model averaging object containing outputs of `MuMIn::model.avg()` using delta < 2 (or 4, or 6) to subset the models.  
-  `mod_chl` - the global model object.  
-  `top_modsd2` / `d4` / `d6`  - model selection table for the subset of models with delta < 2 (or 4, or 6).  
-  `top_modsd2_unnested` / `d4` / `d6` - model selection table for the subset of models with delta < 2 (or 4, or 6), but with models removed if they were only a more complex version of a model with lower AICc.  


 

## 07_visualizations  

This folder contains outputs from scripts in `R/Analyses_for_paper/07_visualizations`. At this point the files are exploring medians and long-term trends, but I expect this will be added to.  
  

# Explanation of trend calculations  

## Station selection  

Only SWMP stations that started collecting data before 2013, and that were active as of the end of 2022, are represented here. Only stations that exist for BOTH WQ and NUT data types are represented. Water quality stations that were abnormally deep (long-term median depth > 6m) were removed.  

### Data point inclusion  

See the data processing README files for explanations on data point inclusion/exclusion. Generally, data points flagged as either suspect or rejected were excluded from these analyses.  

### Monthly aggregation  

Again, see the data processing README files. Additionally, see the `Outputs/02_calculated_long-term-trends/data_dictionary_trend_parameters.csv` file for parameters analyzed and transformations made. For WQ and MET, we are generally working with monthly median values. For NUTs, we are working with averaged replicates for each month.

### Trend calculation  

We have generally used GAMs (generalized additive models) to calculate trends. A seasonal term is included, with 12 knots if possible and the number of months represented in the data frame otherwise (e.g. stations where sondes are removed part of the year due to ice). Autocorrelation of residuals is automatically checked for and if present, the model is re-run to account for the autocorrelation. The reported trend in the outputs is the LINEAR trend through time (per year) of the parameter. To account for censoring, autocorrelation, and seasonality, we used `mgcv::bam`.    

For NUT parameters: values were log transformed [as of 5/29/2024, this is natural-log; replacing log10, as natural-log yields more interpretable coefficinets; see Gelman et al. 2021], and marked as censored (e.g. below the minimum detection limit, or MDL) or uncensored. This created a response matrix that was used in `mgcv::bam` with `family = cnorm()` to account for censoring.  

For WQ monthly medians, we also used `mgcv::bam` for consistency in outputs. There is no censoring in these parameters, so we used `family = gaussian()`.  

For WQ proportion of DO below 2 and 5: These calculations were made before monthly aggregation - each valid 15-minute data point was marked TRUE/FALSE for below 2 and 5, respectively (in separate columns). During monthly aggregation, the total TRUE for each month was divided by the total number of valid DO points for the month, leading to a proportion per month. Trends were again calculated in `mgcv::bam()` with a seasonal term and an autocorrelation term if necessary. Because this response is a proportion, we used `family = betar()`. The `eps` option, which adjusts exact 0s and 1s, was set to 1/10th of the minimum number of readings per month (1/27900). 

For MET parameters, we again used the `bam` code written for water quality, as the properties are similar. Performed tests on 3 parameters: monthly median air temperature (C), monthly total precipitation (mm), and the monthly median of daily total PAR. Monthly precipitation was square-root transformed before analysis (this produced the best residual diagnostics on 5 stations explored).  


### Seasonal trends  

This part is simpler and rougher: we have not accounted for autocorrelation or any "wiggliness" in the data. We simply split data into four seasons: Winter (Jan, Feb, Mar); Spring (Apr, May, Jun); Summer (Jul, Aug, Sep); Fall (Oct, Nov, Dec) and calculated a linear trend. For WQ medians, we used the simple `lm()` function. Nutrients still used `mgcv::bam()` to account for censoring (`family = cnorm()`), and DO proportions also used `mgcv::bam()` with `family = betar()`.  

### Additional  

p-values have NOT been adjusted from any of these analyses, so be wary about declaring any individual trend significant based on its reported p-value. Be especially wary about seasonal p-values, as autocorrelation is not accounted for.  