---
title: "Exploration of Predictor Variables"
output: 
  html_document:
    toc: true
    toc_float: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.height = 7,
                      fig.width = 7)

# packages
library(tidyverse)
library(NADA2)  # for cfit - Kaplan Meier estimation
library(GGally) # for ggpairs
library(corrplot) # for corrplot


# parameters and columns to keep
params_wq <- c("temp_median", "spcond_median", 
               "turb_median")
params_nut <- c("chla_n", "chla_n_cens",
                "nh4f", "nh4f_cens",
                "no23f", "no23f_cens",
                "po4f", "po4f_cens")
params_met <- c("atemp_median", "wspd_median",
                "maxwspd_median", "totprcp_total",
                "dailyPAR_median")
params_trends <- c("temp_median", "spcond_median", "turb_median",
                   "chla_n", "po4f", "nh4f", "no23f",
                   "atemp_median", "dailyPAR_median",
                   "sqrt_precp_total")

# homemade function to use NADA2::cfit and pull out the Kaplan-Meier median
extract_cens_median <- function(df, nut, nut_cens){

  # nut and nut_cens should be entered as character strings
  
  tmp <- df[c(nut, nut_cens)]
  names(tmp) <- c("nut", "nut_cens")

  station <- unique(df$station)
  param <- nut
    
  tmp <- tmp |> 
    na.omit() |> 
    mutate(nut = case_when(nut <=0 ~ 0.0001,
                           .default = nut)) 
  
  if(nrow(tmp) < 5) return(list(station = station,
                                param = param,
                                KMmedian = NA,
                                PctND = NA))
  if(sum(tmp$nut_cens == 0) < 2) return(list(station = station,
                                param = param,
                                KMmedian = NA,
                                PctND = NA))
  
  tmp_fit <- cfit(tmp$nut, tmp$nut_cens, Cdf = FALSE, printstat = FALSE)
  KMmedian <- tmp_fit$KMmedian
  
  KMmedian <- ifelse(is.character(KMmedian),
                     as.numeric(str_remove(KMmedian, "<")),
                     KMmedian)
  
  PctND <- tmp_fit$PctND
  
  return(list(station = station,
              param = param,
              KMmedian = KMmedian,
              PctND = PctND))
}

```

Need to bring everything together: slopes and long-term medians.  

# Data import  

Read in wq, met, nut data. Only keep key parameters (and medians). Calculate long-term medians for every monthly median. Use Kaplan-Meier methods on censored data (NUT). Bind WQ and NUT stations. Find primary SWMP MET station for each reserve and bind to the wq/nut stations on reserve.  

```{r load-data}
load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyWQ.RData"))
load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyNUT.RData"))  
load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyMET.RData")) 

load(here::here("Outputs", "calculated_trends", "long-term-trends.RData"))
load(here::here("Outputs", "calculated_trends", "seasonal_characterization.RData"))

mdat <- readr::read_csv(here::here("helper_files", "sampling_stations.csv"))
```


```{r select-filter-data}
# trends
trnds <- bind_rows(trends_df, trends_met, trends_nut) |> 
  mutate(reserve = substr(station, start = 1, stop = 3),
         station = substr(station, start = 1, stop = 5)) |> 
  filter(parameter %in% params_trends) |> 
  mutate(parameter = str_remove(parameter, "_median"),
         parameter = case_when(parameter == "sqrt_precp_total" ~ "precp",
                               parameter == "chla_n" ~ "chla",
                               .default = parameter),
         parameter = paste0(parameter, "_trend")) |> 
  select(reserve, station, parameter, Slope)

# bind together
trnds_water <- trnds |> 
  filter(parameter %in% c("temp_trend", "spcond_trend", "turb_trend",
                          "chla_trend", "po4f_trend", "nh4f_trend",
                          "no23f_trend")) |> 
  pivot_wider(id_cols = c(reserve, station),
              names_from = parameter,
              values_from = Slope)




# wq, nut, met data
# only keep stations with long-term trend calculations
wq <- wq |> 
  mutate(reserve = substr(station, start = 1, stop = 3),
         station = substr(station, start = 1, stop = 5)) |> 
  filter(station %in% unique(trnds_water$station)) |> 
  select(reserve, station, 
         year, month,
         all_of(params_wq))

nut <- nut |> 
  mutate(reserve = substr(station, start = 1, stop = 3),
         station = substr(station, start = 1, stop = 5)) |> 
  filter(station %in% unique(trnds_water$station)) |> 
  select(reserve, station, 
         year, month,
         all_of(params_nut))  

met <- met |> 
  mutate(reserve = substr(station, start = 1, stop = 3)) |> 
  select(reserve, station, 
         year, month,
         all_of(params_met))


# seasonality  
seas <- seasonal_by_stn |> 
  filter(parameter %in% c("temp_median", "chla_n", "do_mgl_median")) |> 
  mutate(parameter = case_match(parameter,
                                "chla_n" ~ "chla",
                                "do_mgl_median" ~ "do_mgl",
                                "temp_median" ~ "temp"),
         station = substr(station, 1, 5)) |>  
  select(station, parameter, median_norm_ampl) |> 
  filter(station %in% unique(trnds_water$station)) |> 
  pivot_wider(names_from = parameter,
              values_from = median_norm_ampl,
              names_glue = "{parameter}_seas_ampl")

# latitude - only for wq stations for now, since nut stns are linked to wq
lat_wq <- mdat |> 
  janitor::clean_names() |> 
  select(station_full = station_code,
         latitude) |> 
  mutate(station_full = trimws(station_full),
         reserve = substr(station_full, 1, 3),
         station = substr(station_full, 1, 5)) |> 
  filter(str_ends(station_full, "wq"),
         station %in% unique(trnds_water$station)) |> 
  select(reserve, station, latitude)
  

```


```{r calc-medians}
# wq
wq_medians <- wq |> 
  summarize(.by = c(reserve, station),
            across(temp_median:turb_median, function(x) median(x, na.rm = TRUE)))

# met
met_medians <- met |> 
  summarize(.by = c(reserve, station),
            across(atemp_median:dailyPAR_median, function(x) median(x, na.rm = TRUE)))


# nutrients more involved
nut_values <- c("chla_n", "nh4f", "no23f", "po4f")
nut_censoreds <- paste0(nut_values, "_cens")

nut_split <- nut |> 
  split(nut$station)

nut_KMs <- map(nut_split, 
               function(X) map2(nut_values, nut_censoreds,
                                ~extract_cens_median(X, .x, .y )) ) |> 
  bind_rows()

nut_medians <- nut_KMs |> 
  select(station, param, KMmedian) |>
  pivot_wider(id_cols = station,
              names_from = param,
              names_glue = "{param}_median",
              values_from = KMmedian) |> 
  mutate(reserve = substr(station, start = 1, stop = 3)) |> 
  relocate(reserve)
```

```{r join-water-values}
water_medians <- left_join(wq_medians, nut_medians,
                           by = c("reserve", "station"))

# this join will cut out stations where trends weren't calculated
water_all <- left_join(trnds_water, water_medians,
                       by = c("reserve", "station")) |> 
  left_join(lat_wq, by = c("reserve", "station")) |> 
  left_join(seas, by = "station")
```

# Correlation plots  

```{r}
Q <- cor(water_all[3:ncol(water_all)], 
         method = "spearman",
         use = "pairwise.complete.obs")
testRes2 = cor.mtest(water_all[3:ncol(water_all)], conf.level = 0.95)
```

## All  

Used Spearman method for correlation calculation  

Variables are ordered by their loadings on PC1 of a PCA (`order = 'FPC'`)  

**Significant correlations are marked with an asterisk**  

```{r}
corrplot(Q, 
         type = "upper",
         order = 'FPC',
         method = "ellipse",
         p.mat = testRes2$p, 
         sig.level = 0.05,
         insig = "label_sig",
         pch.cex = 2.5,
         pch.col = "gray20",
         tl.pos = "lt",
         tl.cex = 0.8,
         tl.srt = 45)
corrplot(Q, add = TRUE,
         type = "lower",
         order = 'FPC',
         method = "number",
         insig = "n",
         diag = FALSE,
         tl.pos = "n",
         cl.pos = "n")
```



## Significant only  

```{r}
corrplot(Q, 
         type = "full",
         order = 'FPC',
         method = "ellipse",
         p.mat = testRes2$p, 
         sig.level = 0.05,
         addCoef.col = "gray30",
         insig = "blank",
         tl.pos = "lt",
         tl.cex = 0.8,
         tl.srt = 45)
```



# Pairs plots  

Pretty hard to look at; trying my best.  

Log-transforming medians of chl and nutrients first due to their distn's (this would not change spearman correlations calculated above)  

```{r}
water_all2 <- water_all |> 
  mutate(across(c(chla_n_median, nh4f_median, no23f_median, po4f_median),
                function(x) log10(x)))
```

```{r, fig.height = 12, fig.width = 14}
lowerFn <- function(data, mapping, method = "loess", ...) {
  p <- ggplot(data = data, mapping = mapping) +
    geom_point(colour = "navy", alpha = 0.8) +
    geom_smooth(method = method, color = "darkorange", 
                se = FALSE, linewidth = 0.9, ...)
  p
}

ggpairs(water_all2[3:ncol(water_all2)],
        upper = list(continuous = "cor", method = "spearman"),
        lower = list(continuous = wrap(lowerFn)),
        axisLabels = "none")
```


```{r, fig.height = 12, fig.width = 14}
pairs(water_all2[, 3:ncol(water_all2)],
      lower.panel = panel.smooth,
      upper.panel = NULL)
```






# One big PCA  

## Importance of axes  

```{r}
pca_out <- prcomp(Q)
pca_summ <- summary(pca_out)

summary(pca_out)$importance[, 1:6]
```

First 3 axes get us up to 73% of variance explained.  

## Loadings:  

### First 4  

(ordered by PC1, as were the corrplots above)

```{r}
first_pcs <- as.data.frame(summary(pca_out)$rotation[, 1:4])

first_pcs |> arrange(desc(PC1))
```


### PC1  

```{r}
first_pcs |> 
  select(PC1) |> 
  arrange(desc(PC1))
```



### PC2  

```{r}
first_pcs |> 
  select(PC2) |> 
  arrange(desc(PC2))
```


### PC3  

```{r}
first_pcs |> 
  select(PC3) |> 
  arrange(desc(PC3))
```



