---
title: "Seasonality quantification"
output: 
  html_document:
    toc: true
    toc_float: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      error = TRUE,
                      fig.width = 7,
                      fig.height = 7)
```

```{r}
library(dplyr)
library(tidyr)
library(ggplot2)
library(patchwork)

source(here::here("helper_files", "definitions.R"))
source(here::here("helper_files", "functions.R"))

load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyWQ.RData"))
load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyNUT.RData"))

wq <- wq |> 
  mutate(do_proportion_below2 = round(doLessThan2_total / doLessThan2_nValid, 4),
         do_proportion_below5 = round(doLessThan5_total / doLessThan5_nValid, 4)) 
```


From Cloern and Jassby 2008:

1.  Monthly mean chl calculated (will use our monthly values)  
2.  Annual mean determined by averaging monthly means  
    a.  They only did this when all 12 values existed in a calendar year, or when there were 12 consecutive months of data. I don't think this will work for our purposes especially given some sites not sampling in winter months. 
    b.  Probably ought to make some cutoff though to get a legitimate yearly average.  
3.  Defined the month number of the largest monthly mean, within each year.  
4.  Turned that into a probability distribution: "a site with three years of data and annual peaks in March, April and March respectively would have a distribution with March set to 0.67, April to 0.33 and other months to 0."  
    a.  so essentially each month's number is the proportion of available years in which that month had the peak chl.  
5.  Turned the probability dist'n into a frequency dist'n across all sites within a region - which we are not doing.  
6.  Amplitude: (max - min) for each year. This is "highly dependent on the overall biomass level as expressed by the annual mean" so they also normalized: range divided by annual mean.  
    a.  I don't see whether/how they calculated an overall amplitude - guess we'll take the average of whatever amplitudes are available?  
    

I'll start by only calculating these for chl (max), DO (min), and DO proportions (max).  

Sometimes there are multiple peaks within a year so the `peak_month` (month or months containing the maximum reading for the year) and `floor_month` (month or months containing the minimum reading for the year) columns are list columns.  

Need to unlist the column and then assign weights for each month of the year (so in years with only one month of a peak, the weight for the month going into the next weighting will be 1; when there are 3 peaks, each month's weight will be 0.33, etc.)


# Chl a  

```{r}
chl_annual <- annualize(nut, chla_n) |> 
  select(-annual_min, -floor_month) 

chl_weighted_months <- chl_annual |> 
  unnest(cols = peak_month) |> 
  summarize(.by = c(station, year),
            year_factor = length(unique(peak_month))) |> 
  right_join(chl_annual) |> 
  mutate(month_weight_within_year = 1/year_factor) |> 
  unnest(cols = peak_month)

chl_maxes <- chl_annual |> 
  unnest(cols = peak_month) |> 
  group_by(station, year) |> 
  filter(annual_max == max(annual_max, na.rm = TRUE))

stn_distn <- chl_weighted_months |> 
  summarize(.by = c(station, peak_month),
            n_yrs_with_this_peak = n(),
            sum_weights = sum(month_weight_within_year)) 

n_yrs <- chl_annual |> 
  summarize(.by = station,
            nyears = length(unique(year)))

stn_distn <- chl_weighted_months |> 
  summarize(.by = c(station, peak_month),
            n_yrs_with_this_peak = n(),
            sum_weights = sum(month_weight_within_year)) |> 
  left_join(n_yrs, by = "station") |> 
  mutate(prob_of_peak = sum_weights/nyears) |> 
  arrange(station, desc(prob_of_peak)) |> 
  relocate(prob_of_peak, .after = peak_month)

most_likely_month <- stn_distn |> 
  summarize(.by = station,
            most_likely_month = list(peak_month[which(prob_of_peak == max(prob_of_peak))])) |> 
  unnest(cols = most_likely_month)
```


```{r}
p1 <- most_likely_month |> 
  arrange(most_likely_month) |> 
  ggplot() +
  geom_point(aes(x = most_likely_month,
                 y = forcats::fct_inorder(station)),
             alpha = 0) +
  geom_point(data = chl_maxes,
             aes(x = peak_month, y = station),
             shape = 1,
             col = "navy",
             alpha = 0.6) +
  geom_point(data = most_likely_month,
             aes(x = most_likely_month, y = station),
             col = "red3") +
  theme(axis.text.y = element_text(size = rel(0.6))) +
  labs(title = "Chl a",
       x = "Timing of maximum",
       y = "station, ordered by median")
```


```{r}
p2 <- chl_annual |> 
  select(station, year, an_normalized_amplitude) |> 
  group_by(station) |> 
  mutate(median_amplitude = median(an_normalized_amplitude)) |> 
  arrange(median_amplitude) |> 
  ggplot() +
  geom_point(aes(x = an_normalized_amplitude, y = forcats::fct_inorder(station)),
             col = "navy",
             shape = 1,
             alpha = 0.5) +
  geom_point(aes(x = median_amplitude, y = station),
             col = "red3") +
  theme(axis.text.y = element_text(size = rel(0.6))) +
  labs(title = "Chl a",
       x = "Normalized amplitude",
       y = "station, ordered by median")
```

```{r}
p1 + p2
```


# DO %  

```{r}
dopct_annual <- annualize(wq, do_pct_median) |> 
  select(-annual_max, -peak_month) 
```


# DO mg/L  

```{r}
domgl_annual <- annualize(wq, do_mgl_median) |> 
  select(-annual_max, -peak_month) 
```



# proportion DO < 5  

```{r}
doLessThan5_annual <- annualize(wq, do_proportion_below5) |> 
  select(-annual_min, -floor_month) 
```



# proportion DO < 2  

```{r}
doLessThan2_annual <- annualize(wq, do_proportion_below2) |> 
  select(-annual_min, -floor_month) 
```