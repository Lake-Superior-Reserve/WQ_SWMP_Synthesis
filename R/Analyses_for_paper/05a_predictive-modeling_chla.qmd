---
title: "Predictive Modeling - chl a trends"
format: 
  html:
    toc: true
    code-fold: true
warning: false
message: false
error: true
embed-resources: true

---

# Setup  

```{r}
library(tidyverse)
library(MuMIn)
library(doParallel)
library(glmmTMB)
library(tictoc)
library(vegan)
library(ggfortify)
```

```{r}
source(here::here("R", "Analyses_for_paper",
                  "050_setup.R"))
```


Natural-log transforming nutrient medians and turbidity, to ensure linearity of effects and stabilize variance.  

Centering and standardizing (1SD) predictors to make sure model converges and aid in relative interpretation (comparing effect sizes among variables on very different scales); once we have a top model set/averaged model, we can back-transform and interpret slopes in their raw units.  



```{r}
# pick the specific predictors we've agreed on
# center and scale all but response 
dat_chl <- dat_all |> 
  select(reserve,
         chla_trend,
         # lat/temp/par PCA
         tpl_PC1,
         # wq medians
         spcond_median, turb_median.log,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(tpl_PC1:last_col(),
                function(x) as.vector(scale(x))))

formula_chl <- paste0("chla_trend ~ ", paste(names(dat_chl[3:ncol(dat_chl)]), collapse = " + "), " + (1|reserve)")
```


# Models     

## Create and evaluate global models    

### Chl  

```{r}
mod_chl <- glmmTMB(as.formula(formula_chl),
                    data = dat_chl)
performance::check_singularity(mod_chl)
r.squaredGLMM(mod_chl)
summary(mod_chl)
```

Marginal r2 = 0.268  
Cond'l r2 = 0.690  


#### Evaluate diagnostics  

```{r}
# assign model at top so this code chunk can be reused
mod = mod_chl


# this code shows a variety of plots, which is nice
performance::check_model(mod)
# VIFs look fine


# we'll look at other plots ourselves


# pull out pearson residuals
resids <- resid(mod, type = "pearson")

op <- par()

# pull out predictor data frame
preds_df <- mod$frame[2:ncol(mod$frame)]

# set up a 4-plot layout
par(mfrow = c(2, 2))

# plot the main diagnostic graphs
plot(resids ~ fitted.values(mod),
     xlab = "fitted",
     ylab = "residual")
abline(h = 0, col = "red3")
hist(resids, breaks = 20)
qqnorm(resids)
qqline(resids, col = "gray60", lty = 2)
boxplot(resids ~ preds_df$reserve)

# set up a bigger plot layout
par(mfrow = c(4, 5))

# plot residuals against every predictor
for(i in 1:ncol(preds_df)){
  plot(resids ~ preds_df[[i]],
       xlab = names(preds_df)[i],
       ylab = "pearson residuals")
  abline(h = 0, col = "red3")
}

# go back to normal plot layout
par(op)

```

```{r}
# cleanup a bit
rm(dat_all, mod, op, pca_tpl2, preds_df, preds_doLT2)
```



```{r}
#| eval: FALSE
#| 
# establish cluster
cl <- makeCluster(10)  
registerDoParallel(cl)
```



```{r}
#| eval: FALSE
#| 
# run models  

options(na.action = "na.fail")

tic("run models")
mod_subsets <- MuMIn::dredge(mod_chl, eval = TRUE,
                             cluster = cl)
toc()
beepr::beep(8)

```

```
run models: 24736.95 sec elapsed
> beepr::beep(8)
> 24736/60
[1] 412.2667
> 412/60
[1] 6.866667
```

## Investigate candidate models  

about 7 hours to run chl. 65,536 models.

How many with delta < 2 or 6?  

```{r}
sum(mod_subsets$delta<2)
sum(mod_subsets$delta<6)
```

Only 30 under 2! Not bad! 2,026 under 6.  

How many models in the 95% confidence set?

```{r}
mod_subsets$cumuwt <- cumsum(mod_subsets$weight)

as.data.frame(mod_subsets) |> 
  mutate(rownumber = 1:nrow(mod_subsets)) |> 
  select(rownumber, delta, weight, cumuwt) |> 
  filter(cumuwt >= 0.95) |> 
  head()
```

Over 31,000 models in the 95% confidence set - that's almost half of the candidate models.

## Get and investigate top models  

```{r}
top_mods <- get.models(mod_subsets, subset = delta<2)

sw(top_mods)
```

## average for final model  

```{r}
avgd_mod <- model.avg(top_mods)
summary(avgd_mod)
```

## Coefficients from averaged model  

From 'full averaging' method  

Also using 'adjusted SE' - look into this  

```{r}
sumwts <- data.frame(sum_wt = sw(top_mods)) |> 
  rownames_to_column("term")


coeffs <- data.frame(summary(avgd_mod)$coefmat.full) |> 
  rownames_to_column("term") |> 
  left_join(sumwts) |> 
  mutate(ci_low = Estimate - 1.96*Adjusted.SE,
         ci_high = Estimate + 1.96*Adjusted.SE,
         term = str_remove(term, "cond\\("),
         term = str_remove(term, "\\)")) |> 
  filter(term != "(Int)") |> 
  arrange(Estimate) |> 
  mutate(term = fct_inorder(term))

ggplot(coeffs) +
  geom_pointrange(aes(y = term,
                      x = Estimate,
                      xmin = ci_low,
                      xmax = ci_high,
                      col = sum_wt)) +
  khroma::scale_color_batlow(reverse = TRUE) +
  geom_vline(xintercept = 0,
             col = "gray40") +
  labs(title = "Standardized slopes in averaged model for chl a trend",
       x = "Slope",
       y = "Term",
       col = "variable importance")
```


## save things for later  

Need to save the original data frame, full model, model subsets, and other interesting things I've generated. Model subsets are the most important but in order to regenerate things, also need the original data frame and full model.  

```{r}
save(dat_chl, mod_chl, mod_subsets, top_mods, avgd_mod, coeffs,
     file = here::here("Outputs",
                       "06_model_selection",
                       "R_objects",
                       "chla_out.RData"))
```






## other  

```{r}
#| eval: FALSE
#| 
top.mods <- get.models(mod_subsets, subset = delta<2)
avgd <- model.avg(top.mods)
avgd$coefficients
# full = zero method
# subset = natural average method

summary(avgd) # gives standard errors etc.
# Grueber et al. say it's best to report unconditional SE "as it incorporates model selection uncertainty, as opposed to standard SE which only considers sampling variance" 

# importances
sw(avgd)
```

"Full" coefficient is the 'zero method' in Grueber et al (coefficient shrinkage); 'subset' is 'natural average' method (does not create shrinkage).  


```{r}
#| eval: FALSE
#| 
# turn off cluster
stopCluster(cl)
```

