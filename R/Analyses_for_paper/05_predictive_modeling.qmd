---
title: "Predictive Modeling"
format: 
  html:
    toc: true
    code-fold: true
warning: false
message: false
error: true
embed-resources: true

---

# Setup  

```{r}
library(tidyverse)
library(MuMIn)
library(doParallel)
library(glmmTMB)
library(tictoc)
library(vegan)
library(ggfortify)
```


## Import predictors data frame  

```{r}
dat_all <- read.csv(here::here("Outputs", 
                               "04_compiled_predictors", 
                               "compiled_predictors.csv"))
preds_doLT2 <- read.csv(here::here("Outputs", 
                                   "04_compiled_predictors",
                                   "doLT2_compiled_predictors.csv"))
```



## PCA on temp/PAR/maybeLatitude  

```{r}
tpl <- dat_all |> 
  select(temp_median,
         dailyPAR_median,
         latitude)

pca_tpl <- prcomp(tpl, scale. = TRUE)
biplot(pca_tpl)
pca_tpl
summary(pca_tpl)
autoplot(pca_tpl,
         loadings = TRUE,
         loadings.label = TRUE)


pca_tp <- prcomp(tpl[, 1:2], scale. = TRUE)
biplot(pca_tp)
pca_tp
summary(pca_tp)
autoplot(pca_tp,
         loadings = TRUE,
         loadings.label = TRUE)
```



## Subset for response vars; transform; center and scale predictors (not response)  

For now, only pulling water temp rather than running PCA - just trying to make sure model construction will work  

Natural-log transforming nutrient medians and turbidity, to ensure linearity of effects and stabilize variance.  

Centering and standardizing (1SD) predictors to make sure model converges and aid in relative interpretation (comparing effect sizes among variables on very different scales); once we have a top model set/averaged model, we can back-transform and interpret slopes in their raw units.  


```{r}
# in previous modeling, log-transformed nutrient and turb medians only
# had made histograms at some point
dat_all2 <- dat_all |> 
  mutate(across(c(chla_median,
                  nh4f_median,
                  no23f_median,
                  po4f_median,
                  turb_median),
                function(x) log(x))) |> 
  rename(turb_median.log = turb_median,
         chla_median.log = chla_median,
         nh4_median.log = nh4f_median,
         no23_median.log = no23f_median,
         po4_median.log = po4f_median)



preds_doLT2 <- preds_doLT2 |> 
  mutate(across(c(chla_median,
                  nh4f_median,
                  no23f_median,
                  po4f_median,
                  turb_median),
                function(x) log(x))) |> 
  rename(turb_median.log = turb_median,
         chla_median.log = chla_median,
         nh4_median.log = nh4f_median,
         no23_median.log = no23f_median,
         po4_median.log = po4f_median)
```

```{r}
#| eval: false

windows()

dat_all |> 
  select(station, do_pct_trend:last_col()) |> 
  pivot_longer(-station,
               names_to = "param",
               values_to = "value") |> 
  ggplot(aes(x = value,
             fill = param)) +
  geom_histogram(bins = 30,
                 col = "gray40") +
  facet_wrap(~param, scales = "free") +
  theme(legend.position = "none")


dat_all2 |> 
  select(station, do_pct_trend:last_col()) |> 
  pivot_longer(-station,
               names_to = "param",
               values_to = "value") |> 
  ggplot(aes(x = value,
             fill = param)) +
  geom_histogram(bins = 30,
                 col = "gray40") +
  facet_wrap(~param, scales = "free")

# transformed vars look much better
```

```{r}
dat_all <- dat_all2
```



```{r}
# pick the specific predictors we've agreed on
# center and scale all but response

dat_chl <- dat_all |> 
  select(reserve,
         chla_trend,
         # wq medians
         temp_median, spcond_median, turb_median.log,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(temp_median:last_col(),
                function(x) as.vector(scale(x))))

formula_chl <- paste0("chla_trend ~ ", paste(names(dat_chl[3:ncol(dat_chl)]), collapse = " + "), " + (1|reserve)")
```


```{r}
# pick the specific predictors we've agreed on
# center and scale all but response

dat_domgl <- dat_all |> 
  select(reserve,
         domgl_trend,
         # wq medians
         temp_median, spcond_median, turb_median.log, domgl_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(temp_median:last_col(),
                function(x) as.vector(scale(x))))

formula_domgl <- paste0("domgl_trend ~ ", paste(names(dat_domgl[3:ncol(dat_domgl)]), collapse = " + "), " + (1|reserve)")

# generate formula without random effect
# due to singular fit when including random effect
formula_fixed_domgl <- paste0("domgl_trend ~ ", paste(names(dat_domgl[3:ncol(dat_domgl)]), collapse = " + "))
```

```{r}
# remove do median from model to see if it helps with the VIFs
dat_domgl2 <- dat_all |> 
  select(reserve,
         domgl_trend,
         # wq medians
         temp_median, spcond_median, turb_median.log, 
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(temp_median:last_col(),
                function(x) as.vector(scale(x))))

formula_domgl2 <- paste0("domgl_trend ~ ", paste(names(dat_domgl2[3:ncol(dat_domgl2)]), collapse = " + "), " + (1|reserve)")

# generate formula without random effect
# due to singular fit when including random effect
formula_fixed_domgl2 <- paste0("domgl_trend ~ ", paste(names(dat_domgl2[3:ncol(dat_domgl2)]), collapse = " + "))

```


```{r}
dat_dopct <- dat_all |> 
  select(reserve,
         dopct_trend = do_pct_trend,
         # wq medians
         temp_median, spcond_median, turb_median.log, dopct_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(temp_median:last_col(),
                function(x) as.vector(scale(x))))

formula_dopct <- paste0("dopct_trend ~ ", paste(names(dat_dopct[3:ncol(dat_dopct)]), collapse = " + "), " + (1|reserve)")

formula_fixed_dopct <- paste0("dopct_trend ~ ", paste(names(dat_dopct[3:ncol(dat_dopct)]), collapse = " + "))
```


```{r}
dat_doLT2 <- preds_doLT2 |> 
  select(reserve,
         doLT2_trend = do_below2_trend,
         # wq medians
         temp_median, spcond_median, turb_median.log, domgl_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median.log, nh4_median.log, no23_median.log, po4_median.log,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) |> 
  mutate(across(temp_median:last_col(),
                function(x) as.vector(scale(x))))

formula_doLT2 <- paste0("doLT2_trend ~ ", paste(names(dat_doLT2[3:ncol(dat_doLT2)]), collapse = " + "), " + (1|reserve)")

formula_fixed_doLT2 <- paste0("doLT2_trend ~ ", paste(names(dat_doLT2[3:ncol(dat_doLT2)]), collapse = " + "))
```

# Models - centered and scaled    

## Create and evaluate global models    

### Chl  

```{r}
mod_chl <- glmmTMB(as.formula(formula_chl),
                    data = dat_chl)
performance::check_singularity(mod_chl)
r.squaredGLMM(mod_chl)
summary(mod_chl)
```

Marginal r2 = 0.268  
Cond'l r2 = 0.690  


#### Evaluate diagnostics  

```{r}
# assign model at top so this code chunk can be reused
mod = mod_chl


# this code shows a variety of plots, which is nice
performance::check_model(mod)
# VIFs look fine


# we'll look at other plots ourselves


# pull out pearson residuals
resids <- resid(mod, type = "pearson")

op <- par()

# pull out predictor data frame
preds_df <- mod$frame[2:ncol(mod$frame)]

# set up a 4-plot layout
par(mfrow = c(2, 2))

# plot the main diagnostic graphs
plot(resids ~ fitted.values(mod),
     xlab = "fitted",
     ylab = "residual")
abline(h = 0, col = "red3")
plot(hist(resids, breaks = 20))
qqnorm(resids)
qqline(resids, col = "gray60", lty = 2)
boxplot(resids ~ preds_df$reserve)

# set up a bigger plot layout
par(mfrow = c(4, 5))

# plot residuals against every predictor
for(i in 1:ncol(preds_df)){
  plot(resids ~ preds_df[[i]],
       xlab = names(preds_df)[i],
       ylab = "pearson residuals")
  abline(h = 0, col = "red3")
}

# go back to normal plot layout
par(op)

```



### DO mgl

```{r}
mod_domgl <- glmmTMB(as.formula(formula_domgl),
                    data = dat_domgl)
performance::check_singularity(mod_domgl)


# drop random factor due to singular fit
mod_domgl <- lm(as.formula(formula_fixed_domgl),
                data = dat_domgl)
performance::check_singularity(mod_domgl)

summary(mod_domgl)$r.squared; summary(mod_domgl)$adj.r.squared
summary(mod_domgl)
```


```{r}
# the version without median do as a predictor
mod_domgl2 <- glmmTMB(as.formula(formula_domgl2),
                    data = dat_domgl2)
performance::check_singularity(mod_domgl2)


# drop random factor due to singular fit
mod_domgl2 <- lm(as.formula(formula_fixed_domgl2),
                data = dat_domgl2)
performance::check_singularity(mod_domgl2)

summary(mod_domgl2)$r.squared; summary(mod_domgl2)$adj.r.squared
summary(mod_domgl2)

mod = mod_domgl2 
# for the evaluation chunk below
# it does generally look a lot better when we don't include it
# only moderate vif is no23 median, at 5.28
# temp and DO are really interacting
```


#### Evaluate diagnostics  

```{r}
# assign model at top so this code chunk can be reused
mod = mod_domgl


# this code shows a variety of plots, which is nice
performance::check_model(mod)

# what are those VIFs
sort(car::vif(mod), decreasing = TRUE)
# temp, do, no23 medians.


# we'll look at other plots ourselves

# pull out pearson residuals
resids <- resid(mod, type = "pearson")

op <- par()

# pull out predictor data frame
preds_df <- mod$model[2:ncol(mod$model)]

# set up a 4-plot layout
par(mfrow = c(2, 2))

# plot the main diagnostic graphs
plot(resids ~ fitted.values(mod),
     xlab = "fitted",
     ylab = "residual")
abline(h = 0, col = "red3")
hist(resids, breaks = 20)
qqnorm(resids)
qqline(resids, col = "gray60", lty = 2)

# set up a bigger plot layout
par(mfrow = c(4, 5))

# plot residuals against every predictor
for(i in 1:ncol(preds_df)){
  plot(resids ~ preds_df[[i]],
       xlab = names(preds_df)[i],
       ylab = "pearson residuals")
  abline(h = 0, col = "red3")
}

# go back to normal plot layout
par(op)

```


### DO %

```{r}
mod_dopct <- glmmTMB(as.formula(formula_dopct),
                    data = dat_dopct)
performance::check_singularity(mod_dopct)

# drop random factor due to singular fit
mod_dopct <- lm(as.formula(formula_fixed_dopct),
                data = dat_dopct)
performance::check_singularity(mod_dopct)

summary(mod_dopct)$r.squared; summary(mod_dopct)$adj.r.squared
summary(mod_dopct)
```


#### Evaluate diagnostics  

```{r}
# assign model at top so this code chunk can be reused
mod = mod_dopct


# this code shows a variety of plots, which is nice
performance::check_model(mod)

# what are those VIFs
sort(car::vif(mod), decreasing = TRUE)
# no23 is the moderate one, turb, temp, and spcond behind it


# we'll look at other plots ourselves


# pull out pearson residuals
resids <- resid(mod, type = "pearson")

op <- par()

# pull out predictor data frame
preds_df <- mod$model[2:ncol(mod$model)]

# set up a 4-plot layout
par(mfrow = c(2, 2))

# plot the main diagnostic graphs
plot(resids ~ fitted.values(mod),
     xlab = "fitted",
     ylab = "residual")
abline(h = 0, col = "red3")
hist(resids, breaks = 20)
qqnorm(resids)
qqline(resids, col = "gray60", lty = 2)


# set up a bigger plot layout
par(mfrow = c(4, 5))

# plot residuals against every predictor
for(i in 1:ncol(preds_df)){
  plot(resids ~ preds_df[[i]],
       xlab = names(preds_df)[i],
       ylab = "pearson residuals")
  abline(h = 0, col = "red3")
}

# go back to normal plot layout
par(op)

```

### DO < 2  

```{r}
mod_doLT2 <- glmmTMB(as.formula(formula_doLT2),
                    data = dat_doLT2)
performance::check_singularity(mod_doLT2)

# drop random factor due to singular fit
mod_doLT2 <- lm(as.formula(formula_fixed_doLT2),
                data = dat_doLT2)
performance::check_singularity(mod_doLT2)

summary(mod_doLT2)$r.squared; summary(mod_doLT2)$adj.r.squared
summary(mod_doLT2)
```

#### Evaluate diagnostics  

```{r}
# assign model at top so this code chunk can be reused
mod = mod_doLT2

# this code shows a variety of plots, which is nice
performance::check_model(mod)

# I do not like the posterior predictive check for doLT2 at all
# there are a few moderate VIFs too
sort(car::vif(mod), decreasing = TRUE)
# temp and DO medians, no23 median. turb and po4 medians are around 4.


# we'll look at other plots ourselves

# pull out pearson residuals
resids <- resid(mod, type = "pearson")

op <- par()

# pull out predictor data frame
# THIS PART IS DIFFERENT FOR lm vs glmmTMB
preds_df <- mod$model[2:ncol(mod$model)]

# set up a 4-plot layout
par(mfrow = c(2, 2))

# plot the main diagnostic graphs
plot(resids ~ fitted.values(mod),
     xlab = "fitted",
     ylab = "residual")
abline(h = 0, col = "red3")
hist(resids, breaks = 20)
qqnorm(resids)
qqline(resids, col = "gray60", lty = 2)


# set up a bigger plot layout
par(mfrow = c(4, 5))

# plot residuals against every predictor
for(i in 1:ncol(preds_df)){
  plot(resids ~ preds_df[[i]],
       xlab = names(preds_df)[i],
       ylab = "pearson residuals")
  abline(h = 0, col = "red3")
}

# go back to normal plot layout
par(op)

```



# Un-scaled modeling  


## Subset for response vars  

For now, only pulling water temp rather than running PCA - just trying to make sure model construction will work  

```{r}
dat_chl <- dat_all |> 
  select(reserve,
         chla_trend,
         # wq medians
         temp_median, spcond_median, turb_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median, nh4f_median, no23f_median, po4f_median,
         # nut trends
         nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend)

formula_chl <- paste0("chla_trend ~ ", paste(names(dat_chl[3:ncol(dat_chl)]), collapse = " + "), " + (1|reserve)")
```


```{r}
dat_domgl <- dat_all |> 
  select(reserve,
         domgl_trend,
         # wq medians
         temp_median, spcond_median, turb_median, domgl_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median, nh4f_median, no23f_median, po4f_median,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) 

formula_domgl <- paste0("domgl_trend ~ ", paste(names(dat_domgl[3:ncol(dat_domgl)]), collapse = " + "), " + (1|reserve)")

# generate formula without random effect
# due to singular fit when including random effect
formula_fixed_domgl <- paste0("domgl_trend ~ ", paste(names(dat_domgl[3:ncol(dat_domgl)]), collapse = " + "))
```


```{r}
dat_dopct <- dat_all |> 
  select(reserve,
         dopct_trend = do_pct_trend,
         # wq medians
         temp_median, spcond_median, turb_median, dopct_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median, nh4f_median, no23f_median, po4f_median,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend) 

formula_dopct <- paste0("dopct_trend ~ ", paste(names(dat_dopct[3:ncol(dat_dopct)]), collapse = " + "), " + (1|reserve)")

formula_fixed_dopct <- paste0("dopct_trend ~ ", paste(names(dat_dopct[3:ncol(dat_dopct)]), collapse = " + "))
```


```{r}
dat_doLT2 <- preds_doLT2 |> 
  select(reserve,
         doLT2_trend = do_below2_trend,
         # wq medians
         temp_median, spcond_median, turb_median, domgl_median,
         # wq trends
         temp_trend, spcond_trend, turb_trend,
         # nut medians
         chla_median, nh4f_median, no23f_median, po4f_median,
         # nut trends
         chla_trend, nh4f_trend, no23f_trend, po4f_trend,
         # met
         precp_median, precp_trend, dailyPAR_trend)

formula_doLT2 <- paste0("doLT2_trend ~ ", paste(names(dat_doLT2[3:ncol(dat_doLT2)]), collapse = " + "), " + (1|reserve)")

formula_fixed_doLT2 <- paste0("doLT2_trend ~ ", paste(names(dat_doLT2[3:ncol(dat_doLT2)]), collapse = " + "))
```


## Create global models    

### Chl  

```{r}
mod_chl <- glmmTMB(as.formula(formula_chl),
                    data = dat_chl)
performance::check_singularity(mod_chl)
r.squaredGLMM(mod_chl)
summary(mod_chl)
```

Marginal r2 = 0.2877  
Cond'l r2 = 0.7498 

centering/scaling didn't change..... interesting  


### DO mgl

```{r}
mod_domgl <- glmmTMB(as.formula(formula_domgl),
                    data = dat_domgl)
performance::check_singularity(mod_domgl)


# drop random factor due to singular fit
mod_domgl <- lm(as.formula(formula_fixed_domgl),
                data = dat_domgl)
performance::check_singularity(mod_domgl)

summary(mod_domgl)$r.squared; summary(mod_domgl)$adj.r.squared
summary(mod_domgl)
```

### DO %

```{r}
mod_dopct <- glmmTMB(as.formula(formula_dopct),
                    data = dat_dopct)
performance::check_singularity(mod_dopct)

# drop random factor due to singular fit
mod_dopct <- lm(as.formula(formula_fixed_dopct),
                data = dat_dopct)
performance::check_singularity(mod_dopct)

summary(mod_dopct)$r.squared; summary(mod_dopct)$adj.r.squared
summary(mod_dopct)
```

### DO < 2  

```{r}
mod_doLT2 <- glmmTMB(as.formula(formula_doLT2),
                    data = dat_doLT2)
performance::check_singularity(mod_doLT2)

# drop random factor due to singular fit
mod_doLT2 <- lm(as.formula(formula_fixed_doLT2),
                data = dat_doLT2)
performance::check_singularity(mod_doLT2)

summary(mod_doLT2)$r.squared; summary(mod_doLT2)$adj.r.squared
summary(mod_doLT2)
```









# Dredging  



## Dredging  

** everything below has eval: FALSE for the chunk** 

How many models will this be? How long does it take MuMIn to come up with the list, using multiple cores?  

16 predictors: 15 + r.e. of reserve.  


```{r}
#| eval: FALSE
#| 
# can subset for testing the dredging stuff below
dat_test <- dat_chl
formula <- paste0("chla_trend ~ ", paste(names(dat_test[3:ncol(dat_test)]), collapse = " + "), " + (1|reserve)")
mod_test <- glmmTMB(as.formula(formula),
                    data = dat_test)
r.squaredGLMM(mod_test)
```

 

```{r}
#| eval: FALSE
#| 
# establish cluster
cl <- makeCluster(10)  
registerDoParallel(cl)
```


It seems to be keeping the random effect in all models; I don't have to force it.  

```{r}
#| eval: FALSE
#| 
# name models, using cluster, and time it
options(na.action = "na.fail")

tic("identify models")
mod_subsets <- MuMIn::dredge(mod_test, eval = FALSE,
                             cluster = cl)
toc()

# examine
tic("examine models")
mod_subsets2 <- lapply(mod_subsets, as.character) |> 
  bind_rows()
mod_subsets2 <- mod_subsets2[2, ] |> 
  pivot_longer(1:ncol(mod_subsets2),
               names_to = "model",
               values_to = "call")
toc()
```

```{r}
#| eval: FALSE
#| 
# run models  
tic("run models")
mod_subsets <- MuMIn::dredge(mod_test, eval = TRUE,
                             cluster = cl)
toc()
beepr::beep(8)

# not using cluster for this call
# times below are for # of predictors in addition to the random effect
# 6 predictors: 14.72 seconds
# 10 predictors: 4.4 minutes
# if this holds, 17 predictors should take ~9.5 hours  
# 6 predictors a second time was ~16 seconds
# 10 predictors a second time: 4.4 minutes

# even though it says it's not using the cluster, this step still runs
# almost twice as fast when I include it as an argument
# (at least for 6 predictors - 29s vs. 15-16s)  
```

object size when eval=TRUE for 6 predictors was 120 bytes
for 10 predictors, also just 120 bytes

[if it doubles like the # of models do, we'll have 1920 bytes for 10 and
122,880 for 16. 122MB - RAM should be ablet to handle that]


```{r}
#| eval: FALSE
#| 
mods_best <- filter(mod_subsets,
                    delta <= 2)

top.mods <- get.models(mod_subsets, subset = delta<2)
avgd <- model.avg(top.mods)
avgd$coefficients

summary(avgd) # gives standard errors etc.
# Grueber et al. say it's best to report unconditional SE "as it incorporates model selection uncertainty, as opposed to standard SE which only considers sampling variance" 

# importances
sw(avgd)
```

"Full" coefficient is the 'zero method' in Grueber et al (coefficient shrinkage); 'subset' is 'natural average' method (does not create shrinkage).  


```{r}
#| eval: FALSE
#| 
tic("entire model")
dat_test <- dat_chl
formula <- paste0("chla_trend ~ ", paste(names(dat_test[3:ncol(dat_test)]), collapse = " + "), " + (1|reserve)")
mod_test <- glmmTMB(as.formula(formula),
                    data = dat_test)

tic("identify models")
mod_subsets <- MuMIn::dredge(mod_test, eval = FALSE,
                             cluster = cl)
toc()

# examine
tic("examine models")
mod_subsets2 <- lapply(mod_subsets, as.character) |> 
  bind_rows()
mod_subsets2 <- mod_subsets2[2, ] |> 
  pivot_longer(1:ncol(mod_subsets2),
               names_to = "model",
               values_to = "call")
toc()
toc()
```

For all 16 predictor vars, took 33 seconds to identify models and 3 seconds to pivot to be able to examine them. There are 65,536 models. Should take ~5 hrs to run them all.   

```{r}
#| eval: FALSE
#| 
# turn off cluster
stopCluster(cl)
```

