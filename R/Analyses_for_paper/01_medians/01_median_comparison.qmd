---
title: "WQ/NUT median calculations"
format: html
toc: true
toc-position: left
echo: true
code-fold: true
warning: false
message: false
error: true
---

Updated output folders 6/3/24.    

```{r}
library(tidyverse)
library(NADA)
```

```{r}
load(here::here("Data", "QAQCd_monthly_byType",
                "SWMP_monthlyWQ.RData"))
load(here::here("Data", "QAQCd_monthly_byType",
                "SWMP_monthlyNUT.RData"))
load(here::here("Data", "QAQCd_monthly_byType",
                "SWMP_monthlyMET.RData"))
stn_mdat <- read_csv(here::here("helper_files",
                                "sampling_stations.csv"))

length(unique(nut$station))
```

## Station Information  

```{r}
# pull relevant station info for combining
# limit to wq stations because only using wq/nut combinations
stn_info <- stn_mdat |> 
  select(`Station Code`,
         `Station Name`,
         Latitude,
         Longitude,
         State,
         `Reserve Name`,
         "Reserve Code" = `NERR Site ID`) |> 
  mutate(State = toupper(State),
         `Reserve Code` = toupper(`Reserve Code`),
         Station = substr(`Station Code`, 1, 5),
         Longitude = as.numeric(Longitude)) |> 
  filter(str_ends(`Station Code`, "wq")) |> 
  relocate(Station) |> 
  select(-`Station Code`)
```

## WQ Medians  

```{r}
wq_meds <- wq |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            yr_start_wq = min(year, na.rm = TRUE),
            yr_end_wq = max(year, na.rm = TRUE),
            across(c(temp_median, 
                     spcond_median,
                     sal_median,
                     do_mgl_median,
                     do_pct_median,
                     ph_median,
                     turb_median),
                   function(x) median(x, na.rm = TRUE)))

wq_nMonths <- wq |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            across(c(temp_median, 
                     spcond_median,
                     sal_median,
                     do_mgl_median,
                     do_pct_median,
                     ph_median,
                     turb_median),
                   function(x) sum(!is.na(x))))
nms <- names(wq_nMonths)[2:ncol(wq_nMonths)]
nms <- str_remove(nms, "_median")
nms <- paste(nms, "nMonths", sep = "_")
names(wq_nMonths)[2:ncol(wq_nMonths)] <- nms


wq_nPoints <- wq |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            across(c(temp_nValid, 
                     spcond_nValid,
                     sal_nValid,
                     do_mgl_nValid,
                     do_pct_nValid,
                     ph_nValid,
                     turb_nValid),
                   function(x) sum(x, na.rm = TRUE)))
nms <- names(wq_nPoints)[2:ncol(wq_nPoints)]
nms <- str_remove(nms, "_nValid")
nms <- paste(nms, "nPoints", sep = "_")
names(wq_nPoints)[2:ncol(wq_nPoints)] <- nms


wq_meds <- left_join(wq_meds, wq_nPoints, by = "station") |> 
  left_join(wq_nMonths, by = "station")
```



## NUT Medians  

Criteria for inclusion:  

-  start year doesn't equal end year  
-  at least 12 values for every nutrient  


```{r}
# nut_meds <- nut |>
#   mutate(station = substr(station, 1, 5)) |>
#   summarize(.by = station,
#             yr_start_nut = min(year, na.rm = TRUE),
#             yr_end_nut = max(year, na.rm = TRUE),
#             across(c(chla_n,
#                      nh4f,
#                      no23f,
#                      po4f),
#                    function(x) median(x, na.rm = TRUE)))
```

### Deal with censoring  


Using the NADA package, we have to remove NAs, but can calculate the median, mean and sd in all the ways. The NADA functions compute the mean slightly too high, so use EnvStats for mean.  

NADA can handle it when there aren't any censored values (e.g. NH4 at acebbnut) but the MLE estimated median is off (apparently this is due to how MLE calculates things).

Below is a function I wrote where I take the nutrient and its censoring column, remove NAs, and calculate the thing.  

It uses the value of the ROS-calculated median (robust Regression on Order Statistics). MLE or Kaplan-Meier values could also be used here, but Helsel calls ROS the most flexible of the methods.  


```{r}
censMed_fun <- function(df, nut, cens){
  tmp <- data.frame("param" = df[[nut]],
                    "censoring" = df[[cens]]) 
  
  # if all values are NA, return NA
  if(sum(is.na(tmp$param)) == nrow(tmp)) return(NA)
  
  # if there aren't at least 10 values, return NA
  if(nrow(tmp) < 5) return(NA)
  
  # otherwise calculate the median
  tmp <- tmp |> 
    mutate(censoring = as.logical(censoring),
           censoring = case_when(param == 0 ~ TRUE,
                                 .default = censoring),
           param = case_when(param == 0 ~ 0.01,
                             .default = param)) |> 
    na.omit()
  # median(cenfit(tmp$param, tmp$censoring))  # kaplan-meier
  median(cenros(tmp$param, tmp$censoring))  # ROS
  #  censtats(tmp$param, tmp$censoring)  # all 3 methods, for comparison - also tells % censored
}


# test <- filter(nut, station == "gndbhnut")  # about 53% of po4 values are censored
# test <- filter(nut, station == "gndhsnut")  # po4 'dropped censored values that exceeded highest non censored value' - still comes out very close to others
# test <- filter(nut, station == "gndblnut")  # >80% of no23 values are censored - median more similar to MLE, but not far off from K-M
# test <- filter(nut, station == "acebbnut")  # has no censored values for nh4 or chl
# test <- filter(nut, station == "owcbrnut")  # has exact 0s
# test <- filter(nut, station == "tjrhpnut")  # only one row in data frame
# censMed_fun(test, "nh4f", "nh4f_cens")
# censMed_fun(test, "no23f", "no23f_cens")
# censMed_fun(test, "po4f", "po4f_cens")
# censMed_fun(test, "chla_n", "chla_n_cens")



censMed_fun2 <- function(df, nut, cens, mdl){
  tmp <- data.frame("param" = df[[nut]],
                    "censoring" = df[[cens]]) 
  
  # if all values are NA, return NA
  if(sum(is.na(tmp$param)) == nrow(tmp)) return(NA)
  
  # if there aren't at least 5 values, return NA
  if(nrow(tmp) < 5) return(NA)
  
  # replace censored values with 1/2 MDL and then calculate the median
  tmp <- tmp |> 
    mutate(censoring = as.logical(censoring),
           censoring = case_when(param == 0 ~ TRUE,
                                 .default = censoring),
           param = case_when(param == 0 ~ 0.01,  # replacing 0 values with a small value (optional)
                             censoring ~ param / 2,  # replace censored values with 1/2 MDL
                             .default = param)) |> 
    na.omit()
  
  median(tmp$param)  # calculate the median of the updated values
}


```

Substitute NO3 for NO23 for the HUD stations.  

```{r}
# copied from when I inserted this into 02_long-term_trend_analyses.Rmd
nut <- nut |> 
  mutate(no23b = case_when(str_starts(station, "hud") ~ no3f,
                           .default = no23f),
         no23_cens_b = case_when(str_starts(station, "hud") ~ no3f_cens,
                           .default = no23f_cens)) |> 
  select(-no23f, -no23f_cens) |> 
  rename(no23f = no23b,
         no23f_cens = no23_cens_b)
```


```{r}
nut_meds_cens <- nut |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            yr_start_nut = min(year, na.rm = TRUE),
            yr_end_nut = max(year, na.rm = TRUE),
            chla_nMonths = sum(!is.na(chla_n)),
            nh4f_nMonths = sum(!is.na(nh4f)),
            no23_nMonths = sum(!is.na(no23f)),
            po4f_nMonths = sum(!is.na(po4f)),
            chla = censMed_fun(.data, nut = "chla_n", cens = "chla_n_cens"),
            nh4f = censMed_fun(.data, nut = "nh4f", cens = "nh4f_cens"),
            no23f = censMed_fun(.data, nut = "no23f", cens = "no23f_cens"),
            po4f = censMed_fun(.data, nut = "po4f", cens = "po4f_cens")
            )


nut_meds_cens2 <- nut |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            yr_start_nut = min(year, na.rm = TRUE),
            yr_end_nut = max(year, na.rm = TRUE),
            chla_nMonths = sum(!is.na(chla_n)),
            nh4f_nMonths = sum(!is.na(nh4f)),
            no23_nMonths = sum(!is.na(no23f)),
            po4f_nMonths = sum(!is.na(po4f)),
            chla = censMed_fun2(.data, nut = "chla_n", cens = "chla_n_cens"),
            nh4f = censMed_fun2(.data, nut = "nh4f", cens = "nh4f_cens"),
            no23f = censMed_fun2(.data, nut = "no23f", cens = "no23f_cens"),
            po4f = censMed_fun2(.data, nut = "po4f", cens = "po4f_cens")
            )

# censMed_fun(nut, "po4f", "po4f_cens")
```
```{r}
# Base plot
plot(nut_meds_cens$no23f, nut_meds_cens2$no23f,
     xlab = "ROS Method", 
     ylab = "1/2 MDL Method", 
     main = "Comparison of no23f Values", 
     pch = 16, # Add a solid circle as a point character
     col = "blue") # Choose a color for the points

# Add a 1:1 reference line
abline(0, 1, col = "red", lty = 2) # Red dashed line for emphasis




# Base plot
plot(nut_meds_cens$no23f, nut_meds_cens2$no23f,
     xlab = "ROS Method", 
     ylab = "1/2 MDL Method", 
     main = "Comparison of no23f Values", 
     pch = 16, # Add a solid circle as a point character
     col = "blue",
     log="xy") # Choose a color for the points

# Add a 1:1 reference line
abline(0, 1, col = "red", lty = 2) # Red dashed line for emphasis

```


```{r}
## if 'nut_meds' chunk above is uncommented and run, can make some graphs to see it's really only affecting the low end (which is as it should be)  

## generally the censored method medians come out lower than the 'regular' method where the fact that values are censored is ignored (also how it should be)

# nut_meds_reg <- nut_meds |> 
#   select(-yr_start_nut, -yr_end_nut) |> 
#   pivot_longer(chla_n:po4f,
#                names_to = "param",
#                values_to = "regular")
# 
# nut_meds_censb <- nut_meds_cens |> 
#   select(-yr_start_nut, -yr_end_nut) |> 
#   rename(chla_n = chla) |> 
#   pivot_longer(chla_n:po4f,
#                names_to = "param",
#                values_to = "censored")
# 
# nut_meds_comp <- full_join(nut_meds_reg, nut_meds_censb)
# 
# ggplot(nut_meds_comp,
#        aes(x = censored,
#            y = regular,
#            col = param)) +
#   geom_point(size = 2) +
#   facet_wrap(~param, scales = "free")
# 
## zoom in on the low end
# nut_meds_comp |> 
#   filter(param != "chla_n") |> 
# ggplot(aes(x = censored,
#            y = regular,
#            col = param)) +
#   geom_point(size = 2) +
#   facet_wrap(~param) +
#   scale_x_continuous(limits = c(0, 0.05)) +
#   scale_y_continuous(limits = c(0, 0.05))
```



## combine and write out  

Join in way that keeps only stations that are in both WQ and NUT data frames. Keep only stations that have different start/end years for both WQ and NUT (i.e. more than one year for WQ, and more than one year for NUT). Keep only stations with at least 12 values for each nutrient.    

```{r}
all_meds <- inner_join(wq_meds,
                       nut_meds_cens,
                       by = "station") |> 
  relocate(c(yr_start_nut, yr_end_nut),
           .after = yr_end_wq) |> 
  filter(yr_end_nut != yr_start_nut,
         yr_end_wq != yr_start_wq,
         chla_nMonths >= 12,
         nh4f_nMonths >= 12,
         no23_nMonths >= 12,
         po4f_nMonths >= 12)
```

Now join all the station info too.  

```{r}
dat_out <- left_join(all_meds, 
                     stn_info,
                     by = c("station" = "Station")) |> 
  select(station, `Station Name`,
         `Reserve Code`, `Reserve Name`,
         State,
         Latitude, Longitude,
         everything()) 
```

```{r}
write.csv(dat_out,
          here::here("Outputs",
                     "01_calculated_medians",
                     "WQ-NUT_overallMedians.csv"))
```


## MET Medians  

First combine the SOS stations  

```{r}
met <- met |> 
  mutate(station = case_when(station == "sostcmet" ~ "soscmmet",
                             .default = station)) 
```


```{r}
met_meds <- met |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            yr_start_met = min(year, na.rm = TRUE),
            yr_end_met = max(year, na.rm = TRUE),
            across(c(atemp_median, 
                     dailyPAR_median,
                     totprcp_total,
                     rh_median,
                     bp_median,
                     wspd_median),
                   function(x) median(x, na.rm = TRUE)))

met_nMonths <- met |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            across(c(atemp_median, 
                     dailyPAR_median,
                     totprcp_total,
                     rh_median,
                     bp_median,
                     wspd_median),
                   function(x) sum(!is.na(x))))
nms <- names(met_nMonths)[2:ncol(met_nMonths)]
nms <- str_remove(nms, "_median")
nms <- str_remove(nms, "_total")
nms <- paste(nms, "nMonths", sep = "_")
names(met_nMonths)[2:ncol(met_nMonths)] <- nms


met_nPoints <- met |> 
  mutate(station = substr(station, 1, 5)) |> 
  summarize(.by = station,
            across(c(atemp_nValid, 
                     dailyPAR_nValid,
                     totprcp_nValid,
                     rh_nValid,
                     bp_nValid,
                     wspd_nValid),
                   function(x) sum(x, na.rm = TRUE)))
nms <- names(met_nPoints)[2:ncol(met_nPoints)]
nms <- str_remove(nms, "_nValid")
nms <- paste(nms, "nPoints", sep = "_")
names(met_nPoints)[2:ncol(met_nPoints)] <- nms


met_meds <- left_join(met_meds, met_nPoints, by = "station") |> 
  left_join(met_nMonths, by = "station")
```

```{r}
write.csv(met_meds,
          here::here("Outputs",
                     "01_calculated_medians",
                     "MET_overallMedians.csv"))
```


