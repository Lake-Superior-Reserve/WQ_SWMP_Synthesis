---
title: "Long-term trend calculations"
output: 
  html_document:
    toc: true
    toc_float: true
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      error = TRUE,
                      fig.width = 7,
                      fig.height = 5)
```

```{r}
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(lubridate)
library(mgcv)
library(gratia)
library(gt)
library(gtsummary)


source(here::here("helper_files", "definitions.R"))
source(here::here("helper_files", "functions.R"))

load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyWQ.RData"))
load(here::here("Data", "QAQCd_monthly_byType", "SWMP_monthlyNUT.RData"))
```

We have 3 chunks of data: WQ, MET, NUT. For each type:  

1.  Load data frame  
2.  Create grid of station/parameter combinations.  
3.  Do appropriate subsetting, based on length of dataset and depth.  
    a.  in `definitions.R` file, an object named `stns_wq_nut_d10` is defined. This vector consists of 105 stations that are labelled "Active", have starting dates before January of 2013, and exist for both WQ and NUT data types.    
4.  Loop through parameters:  
    a.  for each parameter, loop through stations
        i.  run appropriate bam model  
        ii.  extract necessary model info    
        iii.  add model info to type-parameter list
    b.  bind the list to get one data frame per parameter
    c.  make that data frame part of a 'type' output list  
5.  At end of that loop, will have a 'type' list with separate data frames for each parameter. Bind them into one big data frame.  
6.  Get seasonality info on same row as slope coefficient.  
7.  Bind rows on WQ and NUT  
9.  Make sure it's clear that the slope for nutrients is the slope for log10(nut), not raw nut  
10.  Write out the results!  


# Setup  

Subset wq and nut data frames; create param grids.  

**Prioritized parameters**:
*Responses*:  NO3/2, NH4, PO4, Chla, DO, DIN:DIP, proportion of DO data below 2 mg/L; proportion of DO data below 5 mg/L
*Driver variables*: Temp (water and air), Precipitation, Sal, Cond, Stratification, Turbidity, PAR  


```{r}
dat_wq <- wq |> 
  filter(station %in% paste0(stns_wq_nut_d10, "wq")) |> 
  mutate(do_proportion_below2 = round(doLessThan2_total / doLessThan2_nValid, 4),
         do_proportion_below5 = round(doLessThan5_total / doLessThan5_nValid, 4)) |> 
  select(station, year, month, 
         do_pct_median, do_mgl_median,
         temp_median, spcond_median, 
         sal_median, turb_median,
         do_proportion_below2,
         do_proportion_below5)

# may need to treat DO proportions differently from others - not gaussian, but beta

dat_nut <- nut |> 
  filter(station %in% paste0(stns_wq_nut_d10, "nut")) |> 
  select(station, year, month, 
         chla_n, po4f,
         nh4f, no23f,
         chla_n_cens, po4f_cens,
         nh4f_cens, no23f_cens) |> 
  mutate(DIN_to_DIP = (nh4f + no23f) / po4f,
         DIN_to_DIP_cens = case_when(nh4f_cens + no23f_cens + po4f_cens == 0 ~ 0,
                                     .default = 1),
         DIN_to_DIP_censNum = case_when(nh4f_cens + no23f_cens > 0 ~ 1,
                                        .default = 0),
         DIN_to_DIP_censDenom = case_when(po4f_cens == 1 ~ 1,
                                          .default = 0),
         DIN_to_DIP_censBoth = case_when(DIN_to_DIP_censNum + DIN_to_DIP_censDenom == 2 ~ 1,
                                         .default = 0))

# DIN_to_DIP may also need to be treated in a non-gaussian way

```

```{r}
# avoiding all proportion/ratio data at this point
wq_grid <- expand.grid(station = unique(dat_wq$station), 
                       param = names(dat_wq[4:9]))
nut_grid <- expand.grid(station = unique(dat_nut$station), 
                       param = names(dat_nut[4:11]))
```

# WQ  

## trend calcs  

Attempting to use 12 knots for a seasonal smooth. This not possible at all stations (many are not sampled during winter) so at the ones where 12 knots causes a model error, I am allowing the model to choose the number of knots for me by setting it back to the default of k = -1. (This is all happening in the functions `run_bam_wq()` and `run_bam_nut()`).  

```{r}
# wq_grid <- wq_grid[1:3, ]

# set up outputs
trends_out <- list()


# run the loop
for(i in 1:nrow(wq_grid)){
  stn <- as.character(wq_grid$station[i])
  param <- as.character(wq_grid$param[i])
  
  # subset to that stn/param combo
  tmp <- subset_df("wq", dat_wq, stn, param)
  
  # capture some info about the station and time series:
  # long-term median
  # length of time series
  
  # if the below statement is true, there was an error in the model
  # and we need to do something, and move to the next item in the loop
  # if it was false, we can move on
  if(inherits(try(run_bam_wq(tmp, k = 12), silent = TRUE), "try-error")){
    
    # pick our own k:
    # make sure at least 2 values are present for each month from which we want a knot, in case anything was wonky
    knew <- tmp |> 
      summarize(.by = month,
                nVals = sum(!is.na(value))) |> 
      filter(nVals >= 2) |> 
      nrow()
    
    if(inherits(try(run_bam_wq(tmp, k = knew), silent = TRUE), "try-error")){
      
      # if that didn't work, make a blank row in the output:
      out <- data.frame(station = stn,
                        parameter = param,
                        model_error = TRUE)  
      
      # if it did work:
    } else {
      bam_out <- run_bam_wq(tmp, k = knew)
    }
    
    
  } else {
    # run model
    bam_out <- run_bam_wq(tmp, k = 12)
  }
  
  # do all the things to whichever bam_out we got
  # assuming we got one
  
  if(exists("bam_out")){
    
    # save the entire bam object, including autocorrelation info
    file_out <- here::here("Outputs", "calculated_trends", "bam_outputs",
                           paste0(stn, "_", param, "_bam.RData"))
    save(bam_out, file = file_out)
    
    # split it up for further tidying
    rho_info <- bam_out$rho_info  
    bam_out <- bam_out$dat_bam
    
    bam_tidy <- gtsummary::tidy_gam(bam_out, conf.int = TRUE) |> 
      select(-parametric) |> 
      mutate(station = stn,
             parameter = param,
             term = case_match(term,
                               "(Intercept)" ~ "Intercept",
                               "dec_date" ~ "Trend (/yr)",
                               "s(month)" ~ "Seasonality")) |> 
      select(station, parameter, everything())
    
    bam_trend <- bam_tidy |> 
      filter(term == "Trend (/yr)") |> 
      select(station,
             parameter,
             "Slope" = estimate,
             std.error,
             conf.low,
             conf.high,
             statistic,
             p.value)
    
    bam_seas <- bam_tidy |> 
      filter(term == "Seasonality") |> 
      select(station,
             parameter,
             "Seas_edf" = edf,
             "Seas_ref.df" = ref.df,
             "Seas_stat" = statistic,
             "Seas_p.val" = p.value)
    
    bam_r2 <- data.frame(
      station = stn,
      parameter = param,
      R2_adj = summary(bam_out)$r.sq,
      Dev_expl = summary(bam_out)$dev.expl
    )
    
    out <- dplyr::left_join(bam_trend, bam_seas) |> 
      dplyr::left_join(bam_r2) |> 
      mutate(model_error = FALSE)
    
    out <- cbind(out, rho_info)
    
    rm(bam_out)
  }
  
  trends_out[[i]] <- out
}

trends_df <- dplyr::bind_rows(trends_out) |> 
  mutate(sig_trend = case_when(p.value <= 0.05 ~ "yes",
                               is.na(p.value) ~ NA_character_,
                               .default = "no"),
         sig_seasonality = case_when(Seas_p.val <= 0.05 ~ "yes",
                                     is.na(Seas_p.val) ~ NA_character_,
                                     .default = "no"),
         sig_autocorr = case_when(model_refit == TRUE ~ "yes",
                                  is.na(model_refit) ~ NA_character_,
                                  .default = "no"))
```


Originally errored on grbgbwq, with this error: "more knots than unique data values is not allowed". This seems to have been due to lack of year-round sampling and has been fixed.  


Anything that didn't run anyway?  

```{r}
trends_df |> 
  filter(model_error == TRUE) |> 
  select(station, parameter) |> 
  summarize(.by = station,
            parameters = paste(unique(parameter), collapse = "; ")) |> 
  arrange(station) |> 
  gt(caption = "WQ stations where the model did not run")
```


# NUTs  

## trend calcs  

Attempting to use 12 knots for a seasonal smooth. This not possible at all stations (many are not sampled during winter) so at the ones where 12 knots causes a model error, I am allowing the model to choose the number of knots for me by setting it back to the default of k = -1. (This is all happening in the functions `run_bam_wq()` and `run_bam_nut()`).  

```{r}
# for testing
# nut_grid <- nut_grid[1:3, ]

# set up outputs
trends_out <- list()


# run the loop
for(i in 1:nrow(nut_grid)){
  stn <- as.character(nut_grid$station[i])
  param <- as.character(nut_grid$param[i])
  
  # subset to that stn/param combo
  tmp <- subset_df("nut", dat_nut, stn, param)
  
    # capture some info about the station and time series:
  # long-term median
  # length of time series

  
  # if the below statement is true, there was an error in the model
  # and we need to do something, and move to the next item in the loop
  # if it was false, we can move on
  if(inherits(try(run_bam_nut(tmp, k = 12), silent = TRUE), "try-error")){
    
    # pick our own k:
    # make sure at least 2 values are present for each month from which we want a knot, in case anything was wonky
    knew <- tmp |> 
      summarize(.by = month,
                nVals = sum(!is.na(value))) |> 
      filter(nVals >= 2) |> 
      nrow()

    if(inherits(try(run_bam_nut(tmp, k = knew), silent = TRUE), "try-error")){
      # if that didn't work, make a blank row in the output:
      out <- data.frame(station = stn,
                        parameter = param,
                        model_error = TRUE)  
      # if it did work:
    } else {
      bam_out <- run_bam_nut(tmp, k = knew)
    }
    
    
  } else {
    # run model
    bam_out <- run_bam_nut(tmp, k = 12)
  }
  
  # do all the things to whichever bam_out we got
  # assuming we got one
  
  if(exists("bam_out")){
    
    # save the entire bam object, including autocorrelation info
    file_out <- here::here("Outputs", "calculated_trends", "bam_outputs",
                           paste0(stn, "_", param, "_bam.RData"))
    save(bam_out, file = file_out)
    
    # split it up for further tidying
    rho_info <- bam_out$rho_info  
    bam_out <- bam_out$dat_bam
    
    
    bam_tidy <- gtsummary::tidy_gam(bam_out, conf.int = TRUE) |> 
      select(-parametric) |> 
      mutate(station = stn,
             parameter = param,
             term = case_match(term,
                               "(Intercept)" ~ "Intercept",
                               "dec_date" ~ "Trend (/yr)",
                               "s(month)" ~ "Seasonality")) |> 
      select(station, parameter, everything())
    
    bam_trend <- bam_seas <- bam_tidy |> 
      filter(term == "Trend (/yr)") |> 
      select(station,
             parameter,
             "Slope" = estimate,
             std.error,
             conf.low,
             conf.high,
             statistic,
             p.value)
    
    bam_seas <- bam_tidy |> 
      filter(term == "Seasonality") |> 
      select(station,
             parameter,
             "Seas_edf" = edf,
             "Seas_ref.df" = ref.df,
             "Seas_stat" = statistic,
             "Seas_p.val" = p.value)
    
    bam_r2 <- data.frame(
      station = stn,
      parameter = param,
      R2_adj = summary(bam_out)$r.sq,
      Dev_expl = summary(bam_out)$dev.expl
    )
    
    out <- dplyr::left_join(bam_trend, bam_seas) |> 
      dplyr::left_join(bam_r2) |> 
      mutate(model_error = FALSE)
    
    out <- cbind(out, rho_info)
    
    rm(bam_out)
  }
  
  trends_out[[i]] <- out
}
```

```{r}
trends_nut <- dplyr::bind_rows(trends_out) |> 
  mutate(sig_trend = case_when(p.value <= 0.05 ~ "yes",
                               is.na(p.value) ~ NA_character_,
                               .default = "no"),
         sig_seasonality = case_when(Seas_p.val <= 0.05 ~ "yes",
                                     is.na(Seas_p.val) ~ NA_character_,
                                     .default = "no"),
         sig_autocorr = case_when(model_refit == TRUE ~ "yes",
                                  is.na(model_refit) ~ NA_character_,
                                  .default = "no"))
```


Any stations that didn't work?  


```{r}
trends_nut |> 
  filter(model_error == TRUE) |> 
  select(station, parameter) |> 
  summarize(.by = station,
            parameters = paste(unique(parameter), collapse = "; ")) |> 
  arrange(station) |> 
  gt(caption = "Nutrient stations where the model did not run")
```


# Save trend tables  

```{r}
save(trends_df, trends_nut, file = here::here("Outputs", 
                                              "calculated_trends",
                                              "long-term-trends.RData"))

trends_all <- bind_rows(trends_df, trends_nut)
write.csv(trends_all, file = here::here("Outputs",
                                        "calculated_trends",
                                        "long-term-trends.csv"))
```



# Other thoughts  

Present results  

-  graphically:  
    -  stations along x-axis, grouped and colored by region (need to make stn name a factor)  
    -  y-axis will be rate of change. geom_point for slope estimate, geom_errorbar for CI.  
    -  geom_hline for 0.  
    -  facet_wrap by parameter. free_y scales.  
-  tables for each station (Reserves will be interested in this):  
    -  group df by station code, then table with params as rows and the rest as columns.  
    -  no extra shaping, just subsetting.  
    


