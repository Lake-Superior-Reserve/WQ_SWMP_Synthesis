---
title: "Simple plots of qa/qc flagging"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 2
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      error = TRUE,
                      fig.height = 5,
                      fig.width = 7)

library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(patchwork)
library(ggiraph)
source(here::here("QAQC_flags", "functions.R"))
```

# About this html file  

-  Code is present, but folded. If you want to unfold a portion of code, click on the `code` button on the right.  
-  This file was made by using 2 files - This main one is RMarkdown, and for each station, a `.R` script is called to do all the same things (at the moment, just making graphs).      
-  Updated 6/27/23; rather than going station-by-station, will go through groups of 10 stations at a time so graphs can be facted by param x station.  
-  Add'l update 6/27/23: new AQS download of all SWMP WQ and NUT stations, from 2002 - 2022.  


# About the graphs  

-  Hover over bars on the plot to see the Year/Month and # days of {useable/bad} data points.  
    -  a "useable" day was defined as a day where at least one data point was flagged okay, below detection, historical, or corrected.  
    -  a "bad" day was a day where there were 0 data points in the above flags.  
-  Bars are colored by year, just to provide some differentiation. Coloring by month got a little too chaotic.  



### Parameter choices  

In this section we can define which flags and parameters to keep. Currently set to keep:  

-  Flags:  
    -  0 - accepted  
    -  4 - historical  
    -  -4 - below detection  
    -  -5 - above detection
    -  5 - corrected  
-  WQ Parameters:  
    -  Temp  
    -  SpCond  
    -  Sal  
    -  DO %  
    -  DO mg/L  
-  NUT Parameters:  
    -  Chl a (as `chla_n` - does this show up with other names from other reserves?)  
    -  PO4_f (f = filtered)  
    -  NH4_f  
    -  NO23_f  
    -  NO2_f  (some reserves do not analyze separately)  
    -  NO3_f  (some reserves do not analyze separately)  

```{r}
# path to data; change this when files get moved to a better location
path <- here::here("Data_processing", "compiled_by_stn")
```

```{r}
# define which flags to keep: currently just 0, 4, -4, 5, -5
flags_keep <- c("<0>", "<4>", "<-4>", "<5>", "<-5>")

# define which wq parameters to investigate
wq_parms <- c("temp", "spcond", "sal",
             "do_pct", "do_mgl")
wq_keep <- c(wq_parms, paste0("f_", wq_parms))
names(wq_parms) <- paste0("val_", wq_parms)  # for easier pivoting later


# define which nut parameters to investigate
nut_parms <- c("chla_n", "po4f", 
              "nh4f", "no23f", 
              "no2f", "no3f")
nut_keep <- c(nut_parms, paste0("f_", nut_parms))
names(nut_parms) <- paste0("val_", nut_parms)  # for easier pivoting later

```

### Available Stations  

Here I'm keeping stations that:  

-  have both WQ and NUT parameters associated with the same station name  
-  are currently active  
-  have a start date in or before 2011  

```{r}
# go through each of the WQ+NUT stations
# that meet certain criteria:
# currently active, with start date in or before 2011
# both wq and nut at same station
# for now pulling data from Data_processing subfolder but 
# eventually it will live in the main 'data' folder

mstns <- readr::read_csv(here::here("sampling_stations.csv")) %>%  #read.csv threw an error for some reason
  janitor::clean_names() %>%   
  tidyr::separate(active_dates, into = c("start_date", "first_ end_date"),
                  sep = "-",
                  fill = "right",
                  extra = "drop") %>%  # only want the first date if there are multiples
  filter(lubridate::decimal_date(lubridate::my(start_date)) <= 2011.0,
         status == "Active")


# match up wq/nut intersection for stations that meet time length criteria
stns_wq <- str_sub(grep("wq$", mstns$station_code, value = TRUE),
                   end = -3)
stns_nut <- str_sub(grep("nut$", mstns$station_code, value = TRUE),
                   end = -4)
stns_wq_nut <- intersect(stns_wq, stns_nut)

# cleanup  
rm(mstns, stns_nut, stns_wq)
```

**`r length(stns_wq_nut)` stations** throughout the reserve system meet these criteria:  *`r paste(stns_wq_nut, collapse = ", ")`*.  

Only stations from the Gulf of Mexico are visualized here for iteration purposes.  



# Graphs   

Loop through each station to produce graphs (can include stats if needed)  

```{r, results = 'asis'}
# check .RData files, only loop over stations that we have data for
fls <- dir(path, pattern = ".RData$")

toUse <- stns_wq_nut[paste0(stns_wq_nut, "wq.RData") %in% fls & paste0(stns_wq_nut, "nut.RData") %in% fls]


```


```{r, include = FALSE}
# have to generate a girafe object before looping to make the loop work
# this chunk will not appear in output, at all

p <- ggplot(iris, aes(x = Sepal.Width, y = Sepal.Length)) +
  geom_point_interactive()
ggiraph::girafe(ggobj = p)
```


```{r, eval = TRUE, echo = FALSE, results = 'asis'}
# turn this on to work with groups of ~ 10 stations  

x <- toUse
n <- length(toUse) %/% 10  # number of groups for them to mostly contain 10 stations
split_stns <- split(x, cut(seq_along(x), breaks = n, labels = FALSE))

for(i in seq_along(split_stns)){
  stn_vec <- split_stns[[i]]
  cat(paste(i, ": \n", paste(stn_vec, collapse = " "), "\n\n"))
  try(source(here::here("QAQC_flags", "counting_forloop_innards_byGroup.R")))
}
```



```{r, eval = FALSE, echo = FALSE, results = 'asis', fig.width = 7, fig.height = 5}
# turn this chunk on to go station-by-station

for(st in toUse){

  try(source(here::here("QAQC_flags", "counting_forloop_innards.R")))

}
```

